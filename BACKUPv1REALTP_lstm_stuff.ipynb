{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# [10:12 PM]\n",
    "\n",
    "\n",
    "# sources:\n",
    "# https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21\n",
    "# https://www.youtube.com/watch?v=iMIWee_PXl8\n",
    "# https://www.youtube.com/watch?v=9zhrxE5PQgY\n",
    "# https://www.youtube.com/watch?v=2np77NOdnwk\n",
    "# https://skymind.ai/wiki/lstm\n",
    "\n",
    "usingSavedModel = False\n",
    "\n",
    "from datetime import *\n",
    "\n",
    "# IMPORTANT note to self: this is the best working version so far. [as of 1:32 AM]\n",
    "# the other somewhat working but screwed up version is called \n",
    "# v1REALTP_lstm_stuff\n",
    "\n",
    "# Author: Roshan Ram\n",
    "# AndrewID: rram\n",
    "\n",
    "import yfinance as yfinance\n",
    "\n",
    "# import module_manager\n",
    "# module_manager.review()\n",
    "\n",
    "import yfinance as yf # to pull stock data with yf.download(name, yyyy-mm-dd of opening, yyyy-mm-dd of opening)\n",
    "\n",
    "import numpy as np # used for everything lol\n",
    "import pandas as pd # data mainpulation\n",
    "import matplotlib.pyplot as plt # graphing/plotting\n",
    "from keras import *\n",
    "\n",
    "import time, random, copy\n",
    "\n",
    "#####\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd \n",
    "import pickle\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from keras import optimizers\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import logging\n",
    "####\n",
    "\n",
    "# %matplotlib inline \n",
    "#just to make stuff look nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_STEPS = 60\n",
    "batchSize = 20\n",
    "min_max_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock = None\n",
    "# while not isinstance(stock, str):\n",
    "#     stock = input(\"Enter your desired stock. Only alphanumeric characters please.\")\n",
    "# openingInp = input(\"Enter your desired opening date. (yyyy-mm-dd)\") #'2016-01-01'\n",
    "# closingInp = input(\"Enter your desired closing date. (yyyy-mm-dd)\") # '2019-08-01'\n",
    "\n",
    "\n",
    "# data = yf.download(stock, openingInp, closingInp)\n",
    "\n",
    "\n",
    "def getData_LSTM(app):\n",
    "    stock = None\n",
    "#     while not isinstance(stock, str):\n",
    "    stock = app.getUserInput(\"Enter your desired stock. Only alphanumeric characters please.\")\n",
    "    openingInp = app.getUserInput(\"Enter your desired opening date. (yyyy-mm-dd)\") #'2016-01-01'\n",
    "    closingInp = app.getUserInput(\"Enter your desired closing date. (yyyy-mm-dd)\") # '2019-08-01'\n",
    "\n",
    "\n",
    "    data = yf.download(stock, openingInp, closingInp)\n",
    "    return data, stock \n",
    "\n",
    "# data, stock = getData(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def mainFunc1(data):\n",
    "\n",
    "    train_cols = [\"Open\",\"High\",\"Low\",\"Close\", 'Volume']\n",
    "    df_train, df_test = train_test_split(data, train_size=0.8, test_size=0.2, shuffle=False)\n",
    "#     print('df_test:', df_test)\n",
    "#     print(\"Train and Test size\", len(df_train), len(df_test))\n",
    "    # scale the feature MinMax, build array\n",
    "    x = df_train.loc[:,train_cols].values\n",
    "    x_train = min_max_scaler.fit_transform(x)\n",
    "    x_test = min_max_scaler.transform(df_test.loc[:,train_cols])\n",
    "#     df_testJawn = df_test.loc[:,train_cols]\n",
    "    \n",
    "\n",
    "#     print('x_test before\\n\\n', df_test.loc[:,train_cols])\n",
    "#     print((x_train.shape))\n",
    "#     print((x_test.shape))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_test = mainFunc1(data)  # IMP!\n",
    "# # _, _, dfTestJawn = mainFunc1(data)\n",
    "# # # dfTestJawn = dfTestJawn['Close', 'Open'] #.reshape(-1, 1)\n",
    "# # # dfTestJawn = dfTestJawn.reshape(-1, 1)\n",
    "# # train_cols = [\"Open\",\"High\",\"Low\",\"Close\", 'Volume']\n",
    "# # min_max_scaler.transform(dfTestJawn)\n",
    "# x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTimesteps(mat, y_col_index):\n",
    "    # y_col_index is the index of column that would act as output column\n",
    "    # total number of time-series samples would be len(mat) - TIME_STEPS\n",
    "    dim_0 = mat.shape[0] - TIME_STEPS\n",
    "    dim_1 = mat.shape[1]\n",
    "    x = np.zeros((dim_0, TIME_STEPS, dim_1))\n",
    "    y = np.zeros((dim_0,))\n",
    "\n",
    "    for i in (range(dim_0)):\n",
    "        x[i] = mat[i:TIME_STEPS+i]\n",
    "        y[i] = mat[TIME_STEPS+i, y_col_index]\n",
    "    print(\"length of time-series i/o\",x.shape,y.shape)\n",
    "    return x, y\n",
    "\n",
    "def createDataset(mat, batch_size):\n",
    "    no_of_rows_drop = mat.shape[0]%batch_size\n",
    "    if(no_of_rows_drop > 0):\n",
    "        return mat[:-no_of_rows_drop]\n",
    "    else:\n",
    "        return mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mainFunc2(x_test, x_train):\n",
    "    x_t, y_t = createTimesteps(x_train, 3)\n",
    "    x_t = createDataset(x_t, batchSize)\n",
    "    y_t = createDataset(y_t, batchSize)\n",
    "    x_temp, y_temp = createTimesteps(x_test, 3)\n",
    "    x_val, x_test_t = np.split(createDataset(x_temp, batchSize),2)\n",
    "    y_val, y_test_t = np.split(createDataset(y_temp, batchSize),2)\n",
    "    return x_t, y_t, x_val, x_test_t, y_val, y_test_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_t, y_t, x_val, x_test_t, y_val, y_test_t = mainFunc2(x_test, x_train)  # IMP!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function creates a model with MSE as an accuracy-measuring metric\n",
    "\n",
    "def create_model(x_t):\n",
    "    lstm_model = Sequential()\n",
    "    lstm_model.add(LSTM(100, batch_input_shape=(batchSize, TIME_STEPS, x_t.shape[2]), dropout=0.0, recurrent_dropout=0.0, stateful=True, kernel_initializer='random_uniform'))\n",
    "    lstm_model.add(Dropout(0.5))\n",
    "    lstm_model.add(Dense(20,activation='relu'))\n",
    "    lstm_model.add(Dense(1,activation='sigmoid'))\n",
    "    optimizer = optimizers.RMSprop(lr=0.00010000)\n",
    "    lstm_model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    model = lstm_model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not usingSavedModel:\n",
    "#     model = create_model(x_t)  # IMP!\n",
    "    \n",
    "#     today = date.today()\n",
    "#     d4 = today.strftime(\"%b-%d-%Y\")\n",
    "#     # ^Credit: https://www.programiz.com/python-programming/datetime/current-datetime\n",
    "\n",
    "#     fileName = f'{d4}_savedLSTM.h5' \n",
    "#     model.save(fileName)\n",
    "#     print(f\"Saved model `{fileName}` to disk\")\n",
    "# else:\n",
    "#     today = date.today()\n",
    "#     d4 = today.strftime(\"%b-%d-%Y\")\n",
    "#     # ^Credit: https://www.programiz.com/python-programming/datetime/current-datetime\n",
    "\n",
    "#     fileName = f'{d4}_savedLSTM.h5' \n",
    "#     model = load_model(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(x_t, y_t, x_val, y_val, model, numEpochs):\n",
    "    # NOTE TO SELF CHANGE EPOCHS BACK to 300\n",
    "    history = model.fit(x_t, y_t, epochs= numEpochs, verbose=2, batch_size=batchSize,\n",
    "                        shuffle=False, validation_data=(createDataset(x_val, batchSize),\n",
    "                        createDataset(y_val, batchSize))) #callbacks=[csv_logger])\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not usingSavedModel:\n",
    "#     history = trainModel(x_t, y_t, x_val, y_val, model, 300)  # IMP!\n",
    "#     f = open('history.pckl', 'wb')\n",
    "#     pickle.dump(history, f)\n",
    "#     f.close()\n",
    "\n",
    "\n",
    "# else:\n",
    "#     f = open('history.pckl', 'rb')\n",
    "#     history = pickle.load(f)\n",
    "#     f.close()\n",
    "    \n",
    "    \n",
    "# learning source credit:\n",
    "# https://stackoverflow.com/questions/6568007/how-do-i-save-and-restore-multiple-variables-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-378ddb26091c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mfileName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{d4}_savedLSTM.h5'\u001b[0m \u001b[0;31m# <<--- doesn't work for some reason, commenting out for now [9:49 PM]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Saved model `{fileName}` to disk\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#######################################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# update: SAVED MODEL!!! IMPORTANT WILL SAVE TIME ON FRONTEND FOR USER [12/4/19]\n",
    "\n",
    "# now = datetime.now()\n",
    "# dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "\n",
    "# # pickling model to save time on frontend # IMP!\n",
    "# if not usingSavedModel:\n",
    "#     today = date.today()\n",
    "#     d4 = today.strftime(\"%b-%d-%Y\")\n",
    "#     # print(\"date and time =\", dt_string)\t\n",
    "\n",
    "#     # ^Credit: https://www.programiz.com/python-programming/datetime/current-datetime\n",
    "\n",
    "#     fileName = f'{d4}_savedLSTM.h5' # <<--- doesn't work for some reason, commenting out for now [9:49 PM]\n",
    "#     model.save(fileName)\n",
    "#     print(f\"Saved model `{fileName}` to disk\")\n",
    "\n",
    "#######################################################################################################\n",
    "\n",
    "def createPredictions_LSTM(model, x_test_t, y_test_t):\n",
    "    y_pred = model.predict(createDataset(x_test_t, batchSize), batch_size=batchSize)\n",
    "    y_pred = y_pred.flatten()\n",
    "    y_test_t = createDataset(y_test_t, batchSize)\n",
    "    error = mean_squared_error(y_test_t, y_pred)\n",
    "    print(\"Error is\", error, y_pred.shape, y_test_t.shape)\n",
    "    print(y_pred[0:15])\n",
    "    print(y_test_t[0:15])\n",
    "\n",
    "    # convert the predicted value to range of real data\n",
    "    y_pred_org = (y_pred * min_max_scaler.data_range_[3]) + min_max_scaler.data_min_[3]\n",
    "    # min_max_scaler.inverse_transform(y_pred)\n",
    "    y_test_t_org = (y_test_t * min_max_scaler.data_range_[3]) + min_max_scaler.data_min_[3]\n",
    "    # min_max_scaler.inverse_transform(y_test_t)\n",
    "    print(y_pred_org[0:15])\n",
    "    print(y_test_t_org[0:15])\n",
    "    \n",
    "    return y_pred_org, y_test_t_org\n",
    "\n",
    "\n",
    "# y_pred_org, y_test_t_org = createPredictions_LSTM(model, x_test_t, y_test_t) #IMP!\n",
    "\n",
    "\n",
    "\n",
    "# def plotLoss():\n",
    "# Visualize the training data\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plotLoss(history):\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotLoss(history)  # IMP!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test_t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcError(model, x_test_t, y_test_t, y_pred_org, y_test_t_org):\n",
    "    y_pred = model.predict(createDataset(x_test_t, batchSize), batch_size=batchSize)\n",
    "    y_pred = y_pred.flatten()\n",
    "    y_test_t = createDataset(y_test_t, batchSize)\n",
    "    error = mean_squared_error(y_test_t, y_pred)\n",
    "    return (\"Error is\", error, y_pred.shape, y_test_t.shape)\n",
    "\n",
    "    print(y_pred[0:15])\n",
    "    print(y_test_t[0:15])\n",
    "    y_pred_org = (y_pred * min_max_scaler.data_range_[3]) + min_max_scaler.data_min_[3] # min_max_scaler.inverse_transform(y_pred)\n",
    "    y_test_t_org = (y_test_t * min_max_scaler.data_range_[3]) + min_max_scaler.data_min_[3] # min_max_scaler.inverse_transform(y_test_t)\n",
    "    print(y_pred_org[0:15])\n",
    "    print(y_test_t_org[0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcError(model, x_test_t, y_test_t, y_pred_org, y_test_t_org)  # IMP!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plotPrediction(y_pred_org, y_test_t_org):\n",
    "    stime = time.time()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(y_pred_org)\n",
    "#     plt.plot(y_test_t_org)\n",
    "    plt.title('Prediction for next ~ 20 days')\n",
    "    plt.ylabel('Price')\n",
    "    plt.xlabel('Days')\n",
    "    plt.legend(['Prediction', 'Real'], loc='upper left')\n",
    "    plt.show()\n",
    "    print(\"program completed \", time.time() - stime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotPrediction(y_pred_org, y_test_t_org) # IMP!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make the indices numbers for ACTUAL PREDICTION [unfinished 12/5]\n",
    "\n",
    "# closeData = data['Close']\n",
    "# timeData = list(range(len(data.index.values)))\n",
    "# newData = []\n",
    "# for i in range(len(closeData)):\n",
    "#     newData.append([timeData[i], closeData[i]])\n",
    "# # data.rename(index=range(len(timeData)))\n",
    "\n",
    "# data.index = pd.Series(timeData, name = 'Date')\n",
    "# # data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predMainFunc1(data):\n",
    "\n",
    "\n",
    "    train_cols = [\"Open\",\"High\",\"Low\",\"Close\", 'Volume']\n",
    "    df_train = data #let's assume 5 look-ahead days\n",
    "    df_test = np.asarray([[val for val in range(len(data) + 5)]])\n",
    "    print('df_test:', df_test)\n",
    "#     print(\"Train and Test size\", len(df_train), len(df_test))\n",
    "    # scale the feature MinMax, build array\n",
    "    x = df_train.loc[:,train_cols].values\n",
    "    x_train = min_max_scaler.fit_transform(x)\n",
    "    x_test = min_max_scaler.transform(df_test)\n",
    "\n",
    "\n",
    "#     print('x_test before\\n\\n', df_test.loc[:,train_cols])\n",
    "#     print((x_train.shape))\n",
    "#     print((x_test.shape))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return x_train, x_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_test = predMainFunc1(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_test = np.asarray(range(6))\n",
    "\n",
    "# X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
    "# closing_price = model.predict(X_test)\n",
    "# closing_price = scaler.inverse_transform(closing_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
