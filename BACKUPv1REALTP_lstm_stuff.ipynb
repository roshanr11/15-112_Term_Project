{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [10:12 PM]\n",
    "\n",
    "usingSavedModel = True\n",
    "\n",
    "from datetime import *\n",
    "\n",
    "# IMPORTANT note to self: this is the best working version so far. [as of 1:32 AM]\n",
    "# the other somewhat working but screwed up version is called \n",
    "# v1REALTP_lstm_stuff\n",
    "\n",
    "# Author: Roshan Ram\n",
    "# AndrewID: rram\n",
    "\n",
    "import yfinance as yfinance\n",
    "\n",
    "# import module_manager\n",
    "# module_manager.review()\n",
    "\n",
    "import yfinance as yf # to pull stock data with yf.download(name, yyyy-mm-dd of opening, yyyy-mm-dd of opening)\n",
    "\n",
    "import numpy as np # used for everything lol\n",
    "import pandas as pd # data mainpulation\n",
    "import matplotlib.pyplot as plt # graphing/plotting\n",
    "from keras import *\n",
    "\n",
    "import time, random, copy\n",
    "\n",
    "#####\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd \n",
    "# from tqdm._tqdm_notebook import tqdm_notebook\n",
    "import pickle\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from keras import optimizers\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import logging\n",
    "####\n",
    "\n",
    "# %matplotlib inline \n",
    "#just to make stuff look nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_STEPS = 60\n",
    "batchSize = 20\n",
    "min_max_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your desired stock. Only alphanumeric characters please.AAPL\n",
      "Enter your desired opening date. (yyyy-mm-dd)2016-08-01\n",
      "Enter your desired closing date. (yyyy-mm-dd)2019-01-01\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# stock = None\n",
    "# while not isinstance(stock, str):\n",
    "#     stock = input(\"Enter your desired stock. Only alphanumeric characters please.\")\n",
    "# openingInp = input(\"Enter your desired opening date. (yyyy-mm-dd)\") #'2016-01-01'\n",
    "# closingInp = input(\"Enter your desired closing date. (yyyy-mm-dd)\") # '2019-08-01'\n",
    "\n",
    "\n",
    "# data = yf.download(stock, openingInp, closingInp)\n",
    "\n",
    "\n",
    "def getData_LSTM(app):\n",
    "    stock = None\n",
    "#     while not isinstance(stock, str):\n",
    "    stock = app.getUserInput(\"Enter your desired stock. Only alphanumeric characters please.\")\n",
    "    openingInp = app.getUserInput(\"Enter your desired opening date. (yyyy-mm-dd)\") #'2016-01-01'\n",
    "    closingInp = app.getUserInput(\"Enter your desired closing date. (yyyy-mm-dd)\") # '2019-08-01'\n",
    "\n",
    "\n",
    "    data = yf.download(stock, openingInp, closingInp)\n",
    "    return data, stock \n",
    "\n",
    "# data, stock = getData(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def mainFunc1(data):\n",
    "\n",
    "#     TIME_STEPS = 10 # [rram]\n",
    "#     batchSize = 32 # [rram]\n",
    "\n",
    "\n",
    "#     #####\n",
    "#     params = {\n",
    "#         \"batch_size\": 20,  # 20<16<10, 25 was a bust\n",
    "#         \"epochs\": 300,\n",
    "#         \"lr\": 0.00010000,\n",
    "#         \"time_steps\": 60\n",
    "#     }\n",
    "\n",
    "#     iter_changes = \"dropout_layers_0.4_0.4\"\n",
    "\n",
    "#     # INPUT_PATH = PATH_TO_DRIVE_ML_DATA+\"/inputs\"\n",
    "#     OUTPUT_PATH = '~/Desktop'\n",
    "#     TIME_STEPS = params[\"time_steps\"]\n",
    "#     batchSize = params[\"batch_size\"]\n",
    "#     stime = time.time()\n",
    "#     ###\n",
    "\n",
    "\n",
    "    train_cols = [\"Open\",\"High\",\"Low\",\"Close\", 'Volume']\n",
    "    df_train, df_test = train_test_split(data, train_size=0.8, test_size=0.2, shuffle=False)\n",
    "#     print('df_test:', df_test)\n",
    "#     print(\"Train and Test size\", len(df_train), len(df_test))\n",
    "    # scale the feature MinMax, build array\n",
    "    x = df_train.loc[:,train_cols].values\n",
    "    x_train = min_max_scaler.fit_transform(x)\n",
    "    x_test = min_max_scaler.transform(df_test.loc[:,train_cols])\n",
    "    df_testJawn = df_test.loc[:,train_cols]\n",
    "    \n",
    "\n",
    "#     print('x_test before\\n\\n', df_test.loc[:,train_cols])\n",
    "#     print((x_train.shape))\n",
    "#     print((x_test.shape))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return x_train, x_test, df_testJawn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94928408, 0.96021695, 0.96593568, 0.96257574, 0.08238756],\n",
       "       [0.96250964, 0.96699821, 0.97573185, 0.96004414, 0.04440593],\n",
       "       [0.93835392, 0.95004523, 0.94712234, 0.93285646, 0.07318342],\n",
       "       [0.94961197, 0.96846752, 0.96604694, 0.96752893, 0.06531946],\n",
       "       [0.96655375, 0.9733273 , 0.983747  , 0.97083111, 0.01032742],\n",
       "       [0.97136304, 0.98248188, 0.97840362, 0.96620812, 0.03549131],\n",
       "       [0.95201662, 0.97366634, 0.9648224 , 0.97215191, 0.04038042],\n",
       "       [0.97420482, 0.97287529, 0.97294882, 0.96059437, 0.04892592],\n",
       "       [0.95136084, 0.98135179, 0.97027721, 0.97688508, 0.08766271],\n",
       "       [0.97420482, 0.97999543, 0.97562059, 0.9720419 , 0.09153699],\n",
       "       [0.96218158, 0.97468365, 0.96882998, 0.9739131 , 0.04490638],\n",
       "       [0.98152801, 0.993897  , 0.99654906, 0.98921304, 0.07185419],\n",
       "       [0.98819541, 1.0073464 , 1.00077916, 1.00924614, 0.05207489],\n",
       "       [1.00513719, 1.01989161, 1.01391517, 1.00253177, 0.07561604],\n",
       "       [1.0092907 , 1.01118903, 0.97484143, 0.96697854, 0.12484541],\n",
       "       [0.97551639, 0.97739602, 0.96337534, 0.95520097, 0.09505209],\n",
       "       [0.95802824, 0.97671793, 0.96638089, 0.95938357, 0.27755795],\n",
       "       [1.05454154, 1.08544301, 1.05510405, 1.08277385, 0.56173819],\n",
       "       [1.07039023, 1.1602623 , 1.08894585, 1.14760599, 0.50670138],\n",
       "       [1.14088971, 1.16433103, 1.1460536 , 1.15421035, 0.2186021 ],\n",
       "       [1.15149198, 1.17009498, 1.16375383, 1.16609809, 0.13878843],\n",
       "       [1.16591986, 1.17292048, 1.16030272, 1.144524  , 0.14040022],\n",
       "       [1.1301782 , 1.15382009, 1.13536684, 1.14606499, 0.10993631],\n",
       "       [1.1682151 , 1.17608502, 1.16520089, 1.16400671, 0.11955833],\n",
       "       [1.14449668, 1.16839975, 1.15930087, 1.14914698, 0.13068767],\n",
       "       [1.16581045, 1.18930833, 1.17076696, 1.16389653, 0.14341985],\n",
       "       [1.17510115, 1.18490056, 1.17700093, 1.17358288, 0.09225135],\n",
       "       [1.16482678, 1.18693501, 1.17778026, 1.17897645, 0.17243911],\n",
       "       [1.19248006, 1.22163202, 1.21273517, 1.2128785 , 0.16938267],\n",
       "       [1.21095205, 1.26842226, 1.23154851, 1.25976892, 0.23829783],\n",
       "       [1.26188662, 1.28232365, 1.25325615, 1.23643381, 0.18716514],\n",
       "       [1.24767739, 1.25983281, 1.24123342, 1.23181065, 0.14609523],\n",
       "       [1.218166  , 1.25045213, 1.23911828, 1.23192083, 0.07503997],\n",
       "       [1.22417745, 1.25825053, 1.24757882, 1.23676401, 0.0736978 ],\n",
       "       [1.24549139, 1.25655513, 1.25325615, 1.24413878, 0.06965041],\n",
       "       [1.25150284, 1.27735092, 1.26683737, 1.2637315 , 0.09003364],\n",
       "       [1.27183294, 1.29769437, 1.29566956, 1.28310404, 0.11243659],\n",
       "       [1.28429331, 1.33103537, 1.30112437, 1.31920749, 0.15698977],\n",
       "       [1.31817686, 1.38494574, 1.33440936, 1.34177219, 0.37128877],\n",
       "       [1.35380911, 1.39183996, 1.37448512, 1.37039086, 0.31702801],\n",
       "       [1.37457651, 1.39534355, 1.38149843, 1.37842604, 0.15833591],\n",
       "       [1.38091602, 1.40088159, 1.36446627, 1.36202532, 0.21746389],\n",
       "       [1.35074868, 1.37466106, 1.32216411, 1.32052846, 0.22698542],\n",
       "       [1.30287471, 1.352283  , 1.31559619, 1.30071555, 0.26011476],\n",
       "       [1.29303747, 1.31250012, 1.26839586, 1.26802429, 0.27898568],\n",
       "       [1.26090278, 1.34018996, 1.26939771, 1.32878383, 0.24150152],\n",
       "       [1.33664886, 1.34810132, 1.30591111, 1.29818395, 0.37611321],\n",
       "       [1.32112805, 1.38596305, 1.33630197, 1.35696212, 0.30077376],\n",
       "       [1.34550226, 1.36889694, 1.33574533, 1.32867365, 0.20419445],\n",
       "       [1.30615363, 1.3249322 , 1.2773016 , 1.2630711 , 0.25588927],\n",
       "       [1.25849814, 1.31250012, 1.27563168, 1.26703368, 0.1999401 ],\n",
       "       [1.26625862, 1.28729656, 1.25537128, 1.2684645 , 0.1556864 ],\n",
       "       [1.28527715, 1.31735989, 1.29822991, 1.28673642, 0.15056249],\n",
       "       [1.29117936, 1.30696208, 1.27752413, 1.26064951, 0.84341418],\n",
       "       [1.24789604, 1.30583181, 1.27017704, 1.29510179, 0.16135355],\n",
       "       [1.27992132, 1.32346306, 1.30435262, 1.31051191, 0.13012255],\n",
       "       [1.29358401, 1.33397383, 1.30502052, 1.2910292 , 0.1244544 ],\n",
       "       [1.32440713, 1.36437621, 1.34709999, 1.3408916 , 0.18610554],\n",
       "       [1.33500923, 1.35759495, 1.35244354, 1.34958735, 0.11395486],\n",
       "       [1.36954857, 1.39805609, 1.37838144, 1.3663181 , 0.12063485],\n",
       "       [1.36189749, 1.40461127, 1.38149843, 1.3885526 , 0.1324487 ],\n",
       "       [1.39250196, 1.44382918, 1.41656459, 1.41926266, 0.17091885],\n",
       "       [1.40048093, 1.43117101, 1.38261154, 1.37435344, 0.20461928],\n",
       "       [1.36965797, 1.38664114, 1.31414896, 1.33362684, 0.21992635],\n",
       "       [1.30680957, 1.34584095, 1.30991869, 1.32790324, 0.18095874],\n",
       "       [1.32243962, 1.37375688, 1.33273961, 1.36202532, 0.15337019],\n",
       "       [1.34233258, 1.36335907, 1.26372038, 1.24634018, 0.30360137],\n",
       "       [1.22275664, 1.28594037, 1.22219755, 1.22531647, 0.41437541],\n",
       "       [1.2872445 , 1.32414115, 1.2725147 , 1.30963132, 0.28715808],\n",
       "       [1.29533288, 1.31227403, 1.2773016 , 1.25734733, 0.19217265],\n",
       "       [1.27095851, 1.32538438, 1.27162411, 1.31007153, 0.17618405],\n",
       "       [1.30779325, 1.32142861, 1.30034504, 1.29950476, 0.11351708],\n",
       "       [1.25926333, 1.28865291, 1.22976733, 1.24259779, 0.20998497],\n",
       "       [1.26144932, 1.30583181, 1.27908262, 1.27881125, 0.21493377],\n",
       "       [1.28035845, 1.32956606, 1.29589226, 1.2935608 , 0.1722849 ],\n",
       "       [1.23707512, 1.32832284, 1.24869193, 1.3164557 , 0.27153661],\n",
       "       [1.31107233, 1.33939874, 1.24691075, 1.23236105, 0.29300432],\n",
       "       [1.25762387, 1.30718817, 1.27151285, 1.28420482, 0.18286802],\n",
       "       [1.23784015, 1.29373877, 1.2260937 , 1.24567978, 0.35601254],\n",
       "       [1.27380046, 1.28808778, 1.15284421, 1.20099075, 0.34285055],\n",
       "       [1.1859219 , 1.2371157 , 1.1882445 , 1.21265831, 0.25056537],\n",
       "       [1.24855182, 1.29667723, 1.27006561, 1.27385807, 0.26746832],\n",
       "       [1.27227024, 1.31826407, 1.27218075, 1.31084211, 0.46610008],\n",
       "       [1.16843375, 1.21982367, 1.14549696, 1.14859659, 0.79448329],\n",
       "       [1.11105043, 1.1151673 , 1.0646777 , 1.08376446, 0.54410795],\n",
       "       [1.0850366 , 1.11889698, 1.10386287, 1.10776014, 0.20303634],\n",
       "       [1.12930377, 1.17924956, 1.13102531, 1.17578428, 0.21837326],\n",
       "       [1.17313364, 1.17992766, 1.16019146, 1.15971392, 0.13816361],\n",
       "       [1.12471313, 1.13347647, 1.11009684, 1.11546511, 0.22773958],\n",
       "       [1.05312057, 1.06385635, 1.01591888, 1.00209139, 0.39458716],\n",
       "       [0.97256537, 1.03367988, 0.98986971, 0.98073748, 0.35227656],\n",
       "       [0.9973767 , 1.00316454, 0.92842026, 0.92096871, 0.49075258],\n",
       "       [0.9371516 , 0.97479661, 0.93921845, 0.9717117 , 0.34825603],\n",
       "       [0.96021424, 1.00870258, 0.96771687, 0.99504681, 0.25323478],\n",
       "       [0.95474916, 0.96044304, 0.9179562 , 0.91062196, 0.30295167],\n",
       "       [0.82763138, 0.85612572, 0.8124234 , 0.81287837, 0.56063879],\n",
       "       [0.8424964 , 0.84256337, 0.82400092, 0.81067697, 0.19548777],\n",
       "       [0.79014103, 0.80108508, 0.77446294, 0.76125478, 0.12086567],\n",
       "       [0.78248995, 0.7824367 , 0.75397968, 0.78690148, 0.33352801],\n",
       "       [0.7526505 , 0.78040242, 0.76088172, 0.78271887, 0.29759992],\n",
       "       [0.80970593, 0.85409127, 0.80596674, 0.85646677, 0.34411412],\n",
       "       [0.87452185, 0.87115739, 0.83680281, 0.84116684, 0.30140654],\n",
       "       [0.84861726, 0.84324146, 0.8293443 , 0.83048988, 0.27913492],\n",
       "       [0.89419616, 0.89534364, 0.87587673, 0.89917459, 0.29178055],\n",
       "       [0.85583121, 0.86652353, 0.82088394, 0.80968637, 0.2971711 ],\n",
       "       [0.75538304, 0.78051538, 0.75576086, 0.78800226, 0.31462325],\n",
       "       [0.77429233, 0.77723788, 0.73216078, 0.71942773, 0.30649663],\n",
       "       [0.68149524, 0.72750902, 0.67683404, 0.73164568, 0.50294053],\n",
       "       [0.75429013, 0.74672237, 0.71768897, 0.72096873, 0.35624436],\n",
       "       [0.74051802, 0.74819168, 0.74017593, 0.7261421 , 0.24029466],\n",
       "       [0.74150186, 0.75553808, 0.74607595, 0.74650524, 0.20319255],\n",
       "       [0.72521587, 0.71609407, 0.69854168, 0.68629609, 0.29079755],\n",
       "       [0.68641378, 0.70784367, 0.67015469, 0.66934514, 0.326458  ],\n",
       "       [0.68564876, 0.69857596, 0.68863408, 0.69279044, 0.22252313],\n",
       "       [0.6924254 , 0.69767178, 0.62963371, 0.63577329, 0.37381093],\n",
       "       [0.63121646, 0.63731919, 0.58744298, 0.59108427, 0.53027139],\n",
       "       [0.59252378, 0.59267637, 0.52432378, 0.52394055, 0.83841861],\n",
       "       [0.49732204, 0.51797021, 0.49048198, 0.48101272, 0.25563158],\n",
       "       [0.49896166, 0.58216543, 0.49192922, 0.59482666, 0.46867995],\n",
       "       [0.58137497, 0.57696661, 0.52922195, 0.58359931, 0.41430278],\n",
       "       [0.59951907, 0.59674509, 0.57909388, 0.5844799 , 0.30659413],\n",
       "       [0.61077712, 0.60623872, 0.60057882, 0.60110082, 0.23408428]])"
      ]
     },
     "execution_count": 702,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_train, x_test = mainFunc1(data)  # IMP!\n",
    "_, _, dfTestJawn = mainFunc1(data)\n",
    "# dfTestJawn = dfTestJawn['Close', 'Open'] #.reshape(-1, 1)\n",
    "# dfTestJawn = dfTestJawn.reshape(-1, 1)\n",
    "train_cols = [\"Open\",\"High\",\"Low\",\"Close\", 'Volume']\n",
    "min_max_scaler.transform(dfTestJawn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTimesteps(mat, y_col_index):\n",
    "    # y_col_index is the index of column that would act as output column\n",
    "    # total number of time-series samples would be len(mat) - TIME_STEPS\n",
    "    dim_0 = mat.shape[0] - TIME_STEPS\n",
    "    dim_1 = mat.shape[1]\n",
    "    x = np.zeros((dim_0, TIME_STEPS, dim_1))\n",
    "    y = np.zeros((dim_0,))\n",
    "\n",
    "    for i in (range(dim_0)):\n",
    "        x[i] = mat[i:TIME_STEPS+i]\n",
    "        y[i] = mat[TIME_STEPS+i, y_col_index]\n",
    "    print(\"length of time-series i/o\",x.shape,y.shape)\n",
    "    return x, y\n",
    "\n",
    "def createDataset(mat, batch_size):\n",
    "    no_of_rows_drop = mat.shape[0]%batch_size\n",
    "    if(no_of_rows_drop > 0):\n",
    "        return mat[:-no_of_rows_drop]\n",
    "    else:\n",
    "        return mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mainFunc2(x_test, x_train):\n",
    "    x_t, y_t = createTimesteps(x_train, 3)\n",
    "    x_t = createDataset(x_t, batchSize)\n",
    "    y_t = createDataset(y_t, batchSize)\n",
    "    x_temp, y_temp = createTimesteps(x_test, 3)\n",
    "    x_val, x_test_t = np.split(createDataset(x_temp, batchSize),2)\n",
    "    y_val, y_test_t = np.split(createDataset(y_temp, batchSize),2)\n",
    "    return x_t, y_t, x_val, x_test_t, y_val, y_test_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of time-series i/o (427, 60, 5) (427,)\n",
      "length of time-series i/o (62, 60, 5) (62,)\n"
     ]
    }
   ],
   "source": [
    "# x_t, y_t, x_val, x_test_t, y_val, y_test_t = mainFunc2(x_test, x_train)  # IMP!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function creates a model with MSE as an accuracy-measuring metric\n",
    "\n",
    "def create_model(x_t):\n",
    "    lstm_model = Sequential()\n",
    "    lstm_model.add(LSTM(100, batch_input_shape=(batchSize, TIME_STEPS, x_t.shape[2]), dropout=0.0, recurrent_dropout=0.0, stateful=True,     kernel_initializer='random_uniform'))\n",
    "    lstm_model.add(Dropout(0.5))\n",
    "    lstm_model.add(Dense(20,activation='relu'))\n",
    "    lstm_model.add(Dense(1,activation='sigmoid'))\n",
    "    optimizer = optimizers.RMSprop(lr=0.00010000)\n",
    "    lstm_model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    model = lstm_model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not usingSavedModel:\n",
    "#     model = create_model(x_t)  # IMP!\n",
    "    \n",
    "#     today = date.today()\n",
    "#     d4 = today.strftime(\"%b-%d-%Y\")\n",
    "#     # ^Credit: https://www.programiz.com/python-programming/datetime/current-datetime\n",
    "\n",
    "#     fileName = f'{d4}_savedLSTM.h5' \n",
    "#     model.save(fileName)\n",
    "#     print(f\"Saved model `{fileName}` to disk\")\n",
    "# else:\n",
    "#     today = date.today()\n",
    "#     d4 = today.strftime(\"%b-%d-%Y\")\n",
    "#     # ^Credit: https://www.programiz.com/python-programming/datetime/current-datetime\n",
    "\n",
    "#     fileName = f'{d4}_savedLSTM.h5' \n",
    "#     model = load_model(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(x_t, y_t, x_val, y_val, model, numEpochs):\n",
    "    # NOTE TO SELF CHANGE EPOCHS BACK to 300\n",
    "    history = model.fit(x_t, y_t, epochs= numEpochs, verbose=2, batch_size=batchSize,\n",
    "                        shuffle=False, validation_data=(createDataset(x_val, batchSize),\n",
    "                        createDataset(y_val, batchSize))) #callbacks=[csv_logger])\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not usingSavedModel:\n",
    "#     history = trainModel(x_t, y_t, x_val, y_val, model, 300)  # IMP!\n",
    "#     f = open('history.pckl', 'wb')\n",
    "#     pickle.dump(history, f)\n",
    "#     f.close()\n",
    "\n",
    "\n",
    "# else:\n",
    "#     f = open('history.pckl', 'rb')\n",
    "#     history = pickle.load(f)\n",
    "#     f.close()\n",
    "    \n",
    "    \n",
    "# learning source credit:\n",
    "# https://stackoverflow.com/questions/6568007/how-do-i-save-and-restore-multiple-variables-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.26188662, 1.28232365, 1.25325615, 1.23643381, 0.18716514],\n",
       "        [1.24767739, 1.25983281, 1.24123342, 1.23181065, 0.14609523],\n",
       "        [1.218166  , 1.25045213, 1.23911828, 1.23192083, 0.07503997],\n",
       "        ...,\n",
       "        [1.17313364, 1.17992766, 1.16019146, 1.15971392, 0.13816361],\n",
       "        [1.12471313, 1.13347647, 1.11009684, 1.11546511, 0.22773958],\n",
       "        [1.05312057, 1.06385635, 1.01591888, 1.00209139, 0.39458716]],\n",
       "\n",
       "       [[1.24767739, 1.25983281, 1.24123342, 1.23181065, 0.14609523],\n",
       "        [1.218166  , 1.25045213, 1.23911828, 1.23192083, 0.07503997],\n",
       "        [1.22417745, 1.25825053, 1.24757882, 1.23676401, 0.0736978 ],\n",
       "        ...,\n",
       "        [1.12471313, 1.13347647, 1.11009684, 1.11546511, 0.22773958],\n",
       "        [1.05312057, 1.06385635, 1.01591888, 1.00209139, 0.39458716],\n",
       "        [0.97256537, 1.03367988, 0.98986971, 0.98073748, 0.35227656]],\n",
       "\n",
       "       [[1.218166  , 1.25045213, 1.23911828, 1.23192083, 0.07503997],\n",
       "        [1.22417745, 1.25825053, 1.24757882, 1.23676401, 0.0736978 ],\n",
       "        [1.24549139, 1.25655513, 1.25325615, 1.24413878, 0.06965041],\n",
       "        ...,\n",
       "        [1.05312057, 1.06385635, 1.01591888, 1.00209139, 0.39458716],\n",
       "        [0.97256537, 1.03367988, 0.98986971, 0.98073748, 0.35227656],\n",
       "        [0.9973767 , 1.00316454, 0.92842026, 0.92096871, 0.49075258]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.32440713, 1.36437621, 1.34709999, 1.3408916 , 0.18610554],\n",
       "        [1.33500923, 1.35759495, 1.35244354, 1.34958735, 0.11395486],\n",
       "        [1.36954857, 1.39805609, 1.37838144, 1.3663181 , 0.12063485],\n",
       "        ...,\n",
       "        [0.6924254 , 0.69767178, 0.62963371, 0.63577329, 0.37381093],\n",
       "        [0.63121646, 0.63731919, 0.58744298, 0.59108427, 0.53027139],\n",
       "        [0.59252378, 0.59267637, 0.52432378, 0.52394055, 0.83841861]],\n",
       "\n",
       "       [[1.33500923, 1.35759495, 1.35244354, 1.34958735, 0.11395486],\n",
       "        [1.36954857, 1.39805609, 1.37838144, 1.3663181 , 0.12063485],\n",
       "        [1.36189749, 1.40461127, 1.38149843, 1.3885526 , 0.1324487 ],\n",
       "        ...,\n",
       "        [0.63121646, 0.63731919, 0.58744298, 0.59108427, 0.53027139],\n",
       "        [0.59252378, 0.59267637, 0.52432378, 0.52394055, 0.83841861],\n",
       "        [0.49732204, 0.51797021, 0.49048198, 0.48101272, 0.25563158]],\n",
       "\n",
       "       [[1.36954857, 1.39805609, 1.37838144, 1.3663181 , 0.12063485],\n",
       "        [1.36189749, 1.40461127, 1.38149843, 1.3885526 , 0.1324487 ],\n",
       "        [1.39250196, 1.44382918, 1.41656459, 1.41926266, 0.17091885],\n",
       "        ...,\n",
       "        [0.59252378, 0.59267637, 0.52432378, 0.52394055, 0.83841861],\n",
       "        [0.49732204, 0.51797021, 0.49048198, 0.48101272, 0.25563158],\n",
       "        [0.49896166, 0.58216543, 0.49192922, 0.59482666, 0.46867995]]])"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error is 0.011127951518004442 (20,) (20,)\n",
      "[0.97150975 0.9691371  0.9660889  0.96314955 0.9606445  0.9571359\n",
      " 0.9509761  0.94549024 0.9381425  0.9294143  0.9199989  0.9118284\n",
      " 0.9044507  0.8964757  0.89083207]\n",
      "[0.98073748 0.92096871 0.9717117  0.99504681 0.91062196 0.81287837\n",
      " 0.81067697 0.76125478 0.78690148 0.78271887 0.85646677 0.84116684\n",
      " 0.83048988 0.89917459 0.80968637]\n",
      "[191.39166 191.1761  190.89917 190.63214 190.40454 190.08578 189.52617\n",
      " 189.02779 188.36023 187.56729 186.71188 185.9696  185.29935 184.57481\n",
      " 184.06209]\n",
      "[192.22999573 186.80000305 191.41000366 193.52999878 185.86000061\n",
      " 176.97999573 176.77999878 172.28999329 174.61999512 174.24000549\n",
      " 180.94000244 179.55000305 178.58000183 184.82000732 176.69000244]\n"
     ]
    }
   ],
   "source": [
    "# update: SAVED MODEL!!! IMPORTANT WILL SAVE TIME ON FRONTEND FOR USER [12/4/19]\n",
    "\n",
    "# now = datetime.now()\n",
    "# dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "\n",
    "# pickling model to save time on frontend\n",
    "if not usingSavedModel:\n",
    "    today = date.today()\n",
    "    d4 = today.strftime(\"%b-%d-%Y\")\n",
    "    # print(\"date and time =\", dt_string)\t\n",
    "\n",
    "    # ^Credit: https://www.programiz.com/python-programming/datetime/current-datetime\n",
    "\n",
    "    fileName = f'{d4}_savedLSTM.h5' # <<--- doesn't work for some reason, commenting out for now [9:49 PM]\n",
    "    model.save(fileName)\n",
    "    print(f\"Saved model `{fileName}` to disk\")\n",
    "#######################################################################################################\n",
    "\n",
    "def createPredictions_LSTM(model, x_test_t, y_test_t):\n",
    "    y_pred = model.predict(createDataset(x_test_t, batchSize), batch_size=batchSize)\n",
    "    y_pred = y_pred.flatten()\n",
    "    y_test_t = createDataset(y_test_t, batchSize)\n",
    "    error = mean_squared_error(y_test_t, y_pred)\n",
    "    print(\"Error is\", error, y_pred.shape, y_test_t.shape)\n",
    "    print(y_pred[0:15])\n",
    "    print(y_test_t[0:15])\n",
    "\n",
    "    # convert the predicted value to range of real data\n",
    "    y_pred_org = (y_pred * min_max_scaler.data_range_[3]) + min_max_scaler.data_min_[3]\n",
    "    # min_max_scaler.inverse_transform(y_pred)\n",
    "    y_test_t_org = (y_test_t * min_max_scaler.data_range_[3]) + min_max_scaler.data_min_[3]\n",
    "    # min_max_scaler.inverse_transform(y_test_t)\n",
    "    print(y_pred_org[0:15])\n",
    "    print(y_test_t_org[0:15])\n",
    "    \n",
    "    return y_pred_org, y_test_t_org\n",
    "\n",
    "\n",
    "# y_pred_org, y_test_t_org = createPredictions_LSTM(model, x_test_t, y_test_t) #IMP!\n",
    "\n",
    "\n",
    "\n",
    "# def plotLoss():\n",
    "# Visualize the training data\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plotLoss(history):\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotLoss(history)  # IMP!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test_t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcError(model, x_test_t, y_test_t, y_pred_org, y_test_t_org):\n",
    "    y_pred = model.predict(createDataset(x_test_t, batchSize), batch_size=batchSize)\n",
    "    y_pred = y_pred.flatten()\n",
    "    y_test_t = createDataset(y_test_t, batchSize)\n",
    "    error = mean_squared_error(y_test_t, y_pred)\n",
    "    return (\"Error is\", error, y_pred.shape, y_test_t.shape)\n",
    "\n",
    "    print(y_pred[0:15])\n",
    "    print(y_test_t[0:15])\n",
    "    y_pred_org = (y_pred * min_max_scaler.data_range_[3]) + min_max_scaler.data_min_[3] # min_max_scaler.inverse_transform(y_pred)\n",
    "    y_test_t_org = (y_test_t * min_max_scaler.data_range_[3]) + min_max_scaler.data_min_[3] # min_max_scaler.inverse_transform(y_test_t)\n",
    "    print(y_pred_org[0:15])\n",
    "    print(y_test_t_org[0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Error is', 0.010533800915214594, (20,), (20,))"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calcError(model, x_test_t, y_test_t, y_pred_org, y_test_t_org)  # IMP!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plotPrediction(y_pred_org, y_test_t_org):\n",
    "    stime = time.time()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(y_pred_org)\n",
    "    plt.plot(y_test_t_org)\n",
    "    plt.title('Prediction vs Real Stock Price')\n",
    "    plt.ylabel('Price')\n",
    "    plt.xlabel('Days')\n",
    "    plt.legend(['Prediction', 'Real'], loc='upper left')\n",
    "    plt.show()\n",
    "    print(\"program completed \", time.time() - stime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotPrediction(y_pred_org, y_test_t_org) # IMP!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the indices numbers\n",
    "\n",
    "closeData = data['Close']\n",
    "timeData = list(range(len(data.index.values)))\n",
    "newData = []\n",
    "for i in range(len(closeData)):\n",
    "    newData.append([timeData[i], closeData[i]])\n",
    "# data.rename(index=range(len(timeData)))\n",
    "\n",
    "data.index = pd.Series(timeData, name = 'Date')\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predMainFunc1(data):\n",
    "\n",
    "#     TIME_STEPS = 10 # [rram]\n",
    "#     batchSize = 32 # [rram]\n",
    "\n",
    "\n",
    "#     #####\n",
    "#     params = {\n",
    "#         \"batch_size\": 20,  # 20<16<10, 25 was a bust\n",
    "#         \"epochs\": 300,\n",
    "#         \"lr\": 0.00010000,\n",
    "#         \"time_steps\": 60\n",
    "#     }\n",
    "\n",
    "#     iter_changes = \"dropout_layers_0.4_0.4\"\n",
    "\n",
    "#     # INPUT_PATH = PATH_TO_DRIVE_ML_DATA+\"/inputs\"\n",
    "#     OUTPUT_PATH = '~/Desktop'\n",
    "#     TIME_STEPS = params[\"time_steps\"]\n",
    "#     batchSize = params[\"batch_size\"]\n",
    "#     stime = time.time()\n",
    "#     ###\n",
    "\n",
    "\n",
    "    train_cols = [\"Open\",\"High\",\"Low\",\"Close\", 'Volume']\n",
    "    df_train, df_test = data, pd.Series(len(data) + 5) #let's assume 5 look-ahead days\n",
    "#     print('df_test:', df_test)\n",
    "#     print(\"Train and Test size\", len(df_train), len(df_test))\n",
    "    # scale the feature MinMax, build array\n",
    "    x = df_train.loc[:,train_cols].values\n",
    "    x_train = min_max_scaler.fit_transform(x)\n",
    "    x_test = min_max_scaler.transform(df_test.loc[:,train_cols])\n",
    "\n",
    "\n",
    "#     print('x_test before\\n\\n', df_test.loc[:,train_cols])\n",
    "#     print((x_train.shape))\n",
    "#     print((x_test.shape))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return x_train, x_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexingError",
     "evalue": "Too many indexers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-676-df1ff1c378ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredMainFunc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-675-b83b8b03e970>\u001b[0m in \u001b[0;36mpredMainFunc1\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_max_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_max_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1492\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1494\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1495\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1496\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m         \u001b[0;31m# no multi-index, so validate all of the indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m         \u001b[0;31m# ugly hack for GH #836\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_has_valid_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Too many indexers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexingError\u001b[0m: Too many indexers"
     ]
    }
   ],
   "source": [
    "x_train, x_test = predMainFunc1(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-622-a89e419389d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mclosing_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mclosing_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosing_price\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "# X_test = np.asarray(range(6))\n",
    "\n",
    "# X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
    "# closing_price = model.predict(X_test)\n",
    "# closing_price = scaler.inverse_transform(closing_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # try with real testing data\n",
    "\n",
    "\n",
    "# y_pred = lstm_model.predict(createDataset(x_test_t, batchSize), batch_size=batchSize)\n",
    "# y_pred = y_pred.flatten()\n",
    "# y_test_t = createDataset(y_test_t, batchSize)\n",
    "# error = mean_squared_error(y_test_t, y_pred)\n",
    "# print(\"Error is\", error, y_pred.shape, y_test_t.shape)\n",
    "# print(y_pred[0:15])\n",
    "# print(y_test_t[0:15])\n",
    "# y_pred_org = (y_pred * min_max_scaler.data_range_[3]) + min_max_scaler.data_min_[3] # min_max_scaler.inverse_transform(y_pred)\n",
    "# y_test_t_org = (y_test_t * min_max_scaler.data_range_[3]) + min_max_scaler.data_min_[3] # min_max_scaler.inverse_transform(y_test_t)\n",
    "# print(y_pred_org[0:15])\n",
    "# print(y_test_t_org[0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_update_model = True\n",
    "# if model is None or is_update_model:\n",
    "#     from keras import backend as K\n",
    "#     print(\"Building model...\")\n",
    "#     print(\"checking if GPU available\", K.tensorflow_backend._get_available_gpus())\n",
    "#     model = create_model()\n",
    "    \n",
    "#     es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,\n",
    "#                        patience=40, min_delta=0.0001)\n",
    "    \n",
    "#     mcp = ModelCheckpoint(os.path.join(OUTPUT_PATH,\n",
    "#                           \"best_model.h5\"), monitor='val_loss', verbose=1,\n",
    "#                           save_best_only=True, save_weights_only=False, mode='min', period=1)\n",
    "\n",
    "#     # Not used here. But leaving it here as a reminder for future\n",
    "#     r_lr_plat = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=30, \n",
    "#                                   verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "    \n",
    "#     csv_logger = CSVLogger(os.path.join(OUTPUT_PATH, 'training_log_' + time.ctime().replace(\" \",\"_\") + '.log'), append=True)\n",
    "    \n",
    "#     history = model.fit(x_t, y_t, epochs=params[\"epochs\"], verbose=2, batch_size=batchSize,\n",
    "#                         shuffle=False, validation_data=(createDataset(x_val, batchSize),\n",
    "#                         createDataset(y_val, batchSize)), callbacks=[es, mcp, csv_logger])\n",
    "    \n",
    "#     print(\"saving model...\")\n",
    "#     pickle.dump(model, open(\"lstm_model\", \"wb\"))\n",
    "\n",
    "# # model.evaluate(x_test_t, y_test_t, batch_size=batchSize\n",
    "# y_pred = model.predict(createDataset(x_test_t, batchSize), batch_size=batchSize)\n",
    "# y_pred = y_pred.flatten()\n",
    "# y_test_t = createDataset(y_test_t, batchSize)\n",
    "# error = mean_squared_error(y_test_t, y_pred)\n",
    "# print(\"Error is\", error, y_pred.shape, y_test_t.shape)\n",
    "# print(y_pred[0:15])\n",
    "# print(y_test_t[0:15])\n",
    "\n",
    "# # convert the predicted value to range of real data\n",
    "# y_pred_org = (y_pred * min_max_scaler.data_range_[3]) + min_max_scaler.data_min_[3]\n",
    "# # min_max_scaler.inverse_transform(y_pred)\n",
    "# y_test_t_org = (y_test_t * min_max_scaler.data_range_[3]) + min_max_scaler.data_min_[3]\n",
    "# # min_max_scaler.inverse_transform(y_test_t)\n",
    "# print(y_pred_org[0:15])\n",
    "# print(y_test_t_org[0:15])\n",
    "\n",
    "# # Visualize the training data\n",
    "# from matplotlib import pyplot as plt\n",
    "# plt.figure()\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('Model loss')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# #plt.show()\n",
    "# plt.savefig(os.path.join(OUTPUT_PATH, 'train_vis_BS_'+str(batchSize)+\"_\"+time.ctime()+'.png'))\n",
    "\n",
    "# # load the saved best model from above\n",
    "# saved_model = load_model(os.path.join(OUTPUT_PATH, 'best_model.h5')) # , \"lstm_best_7-3-19_12AM\",\n",
    "# print(saved_model)\n",
    "\n",
    "# y_pred = saved_model.predict(createDataset(x_test_t, batchSize), batch_size=batchSize)\n",
    "# y_pred = y_pred.flatten()\n",
    "# y_test_t = createDataset(y_test_t, batchSize)\n",
    "# error = mean_squared_error(y_test_t, y_pred)\n",
    "# print(\"Error is\", error, y_pred.shape, y_test_t.shape)\n",
    "# print(y_pred[0:15])\n",
    "# print(y_test_t[0:15])\n",
    "# y_pred_org = (y_pred * min_max_scaler.data_range_[3]) + min_max_scaler.data_min_[3] # min_max_scaler.inverse_transform(y_pred)\n",
    "# y_test_t_org = (y_test_t * min_max_scaler.data_range_[3]) + min_max_scaler.data_min_[3] # min_max_scaler.inverse_transform(y_test_t)\n",
    "# print(y_pred_org[0:15])\n",
    "# print(y_test_t_org[0:15])\n",
    "\n",
    "# # Visualize the prediction\n",
    "# from matplotlib import pyplot as plt\n",
    "# plt.figure()\n",
    "# plt.plot(y_pred_org)\n",
    "# plt.plot(y_test_t_org)\n",
    "# plt.title('Prediction vs Real Stock Price')\n",
    "# plt.ylabel('Price')\n",
    "# plt.xlabel('Days')\n",
    "# plt.legend(['Prediction', 'Real'], loc='upper left')\n",
    "# #plt.show()\n",
    "# plt.savefig(os.path.join(OUTPUT_PATH, 'pred_vs_real_BS'+str(batchSize)+\"_\"+time.ctime()+'.png'))\n",
    "# print_time(\"program completed \", stime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
